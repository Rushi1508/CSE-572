{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b092040-d37c-4056-b33e-527019b3eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rushi Parikh\n",
    "# CSE 572\n",
    "# HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a6b605-322f-40a4-bd58-7107b19ba157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (9999, 784)\n",
      "\n",
      "Running K-means with euclidean distance...\n",
      "Cluster distribution: {0.0: 1492, 1.0: 768, 2.0: 1221, 3.0: 770, 4.0: 1446, 5.0: 884, 6.0: 997, 7.0: 724, 8.0: 903, 9.0: 794}\n",
      "\n",
      "Running K-means with cosine distance...\n",
      "Cluster distribution: {0.0: 1066, 1.0: 1082, 2.0: 758, 3.0: 1023, 4.0: 772, 5.0: 1248, 6.0: 1119, 7.0: 945, 8.0: 1005, 9.0: 981}\n",
      "\n",
      "Running K-means with jaccard distance...\n",
      "Cluster distribution: {0.0: 1321, 1.0: 899, 2.0: 676, 3.0: 703, 4.0: 912, 5.0: 927, 6.0: 799, 7.0: 940, 8.0: 1719, 9.0: 1103}\n"
     ]
    }
   ],
   "source": [
    "#Task 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# load the dataset from zip\n",
    "def load_dataset(zip_path='kmeans_data.zip'):\n",
    "    # Extracting the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    \n",
    "    # Find the CSV file\n",
    "    csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(\"No CSV file found in the zip archive\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(csv_files[0])\n",
    "    return data.values  # Return as numpy array\n",
    "\n",
    "# Distance metrics\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Euclidean distance between two points\"\"\"\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    \"\"\"1 - Cosine similarity between two points\"\"\"\n",
    "    dot_product = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if norm_x == 0 or norm_y == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    cosine_sim = dot_product / (norm_x * norm_y)\n",
    "    return 1 - cosine_sim\n",
    "\n",
    "def generalized_jaccard_distance(x, y):\n",
    "    \"\"\"1 - Generalized Jaccard similarity between two points\"\"\"\n",
    "    sum_min = np.sum(np.minimum(x, y))\n",
    "    sum_max = np.sum(np.maximum(x, y))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if sum_max == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    jaccard_sim = sum_min / sum_max\n",
    "    return 1 - jaccard_sim\n",
    "\n",
    "# K-means implementation\n",
    "def kmeans(X, k=3, max_iters=100, distance_metric='euclidean', random_state=None):\n",
    "    # Set random seed\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Get dimensions\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    idx = np.random.choice(n_samples, k, replace=False)\n",
    "    centroids = X[idx]\n",
    "    \n",
    "    # Choose the distance function\n",
    "    if distance_metric == 'euclidean':\n",
    "        distance_function = euclidean_distance\n",
    "    elif distance_metric == 'cosine':\n",
    "        distance_function = cosine_distance\n",
    "    elif distance_metric == 'jaccard':\n",
    "        distance_function = generalized_jaccard_distance\n",
    "    else:\n",
    "        raise ValueError(\"Unknown distance metric\")\n",
    "    \n",
    "    # Initialize labels\n",
    "    labels = np.zeros(n_samples)\n",
    "    \n",
    "    # Main K-means loop\n",
    "    for _ in range(max_iters):\n",
    "        # Assign points to nearest centroid\n",
    "        new_labels = np.zeros(n_samples)\n",
    "        for i in range(n_samples):\n",
    "            # Calculate distance to each centroid\n",
    "            distances = [distance_function(X[i], centroid) for centroid in centroids]\n",
    "            # Assign to the closest centroid\n",
    "            new_labels[i] = np.argmin(distances)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.all(labels == new_labels):\n",
    "            break\n",
    "        \n",
    "        labels = new_labels\n",
    "        \n",
    "        # Update centroids\n",
    "        for j in range(k):\n",
    "            cluster_points = X[labels == j]\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[j] = np.mean(cluster_points, axis=0)\n",
    "    \n",
    "    return centroids, labels\n",
    "\n",
    "# Run K-means with each distance metric\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading dataset...\")\n",
    "    X = load_dataset('kmeans_data.zip')\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    \n",
    "    # Number of clusters\n",
    "    k = 10\n",
    "    \n",
    "    # Run K-means with different distance metrics\n",
    "    metrics = ['euclidean', 'cosine', 'jaccard']\n",
    "    results = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print(f\"\\nRunning K-means with {metric} distance...\")\n",
    "        centroids, labels = kmeans(X, k=k, distance_metric=metric, random_state=42)\n",
    "        \n",
    "        # Count points in each cluster\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        cluster_counts = dict(zip(unique, counts))\n",
    "        \n",
    "        print(f\"Cluster distribution: {cluster_counts}\")\n",
    "        results[metric] = {'centroids': centroids, 'labels': labels}\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afff987-4869-4a09-83cf-1ad96d99a84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (10000, 784)\n",
      "Number of categories in target variable: 10\n",
      "\n",
      "Running K-means with euclidean distance...\n",
      "Cluster distribution: {0.0: 855, 1.0: 715, 2.0: 502, 3.0: 947, 4.0: 1391, 5.0: 804, 6.0: 1741, 7.0: 1354, 8.0: 1038, 9.0: 653}\n",
      "Sum of Squared Errors (SSE): 25413478163.00\n",
      "\n",
      "Running K-means with cosine distance...\n",
      "Cluster distribution: {0.0: 926, 1.0: 635, 2.0: 1812, 3.0: 1067, 4.0: 1382, 5.0: 888, 6.0: 730, 7.0: 801, 8.0: 777, 9.0: 982}\n",
      "Sum of Squared Errors (SSE): 25493586936.00\n",
      "\n",
      "Running K-means with jaccard distance...\n",
      "Cluster distribution: {0.0: 950, 1.0: 690, 2.0: 1084, 3.0: 799, 4.0: 1001, 5.0: 881, 6.0: 1258, 7.0: 668, 8.0: 1397, 9.0: 1272}\n",
      "Sum of Squared Errors (SSE): 25418563596.00\n",
      "\n",
      "--- SSE Comparison ---\n",
      "Euclidean-K-means SSE: 25413478163.00\n",
      "Cosine-K-means SSE: 25493586936.00\n",
      "Jaccard-K-means SSE: 25418563596.00\n",
      "\n",
      "Based on SSE, the best method is Euclidean-K-means with SSE = 25413478163.00\n"
     ]
    }
   ],
   "source": [
    "# Q1 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to load the dataset from zip\n",
    "def load_dataset(zip_path='kmeans_data.zip'):\n",
    "    # Extract the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    \n",
    "    # Load data.csv and label.csv\n",
    "    data = pd.read_csv('data.csv', header=None).values\n",
    "    labels = pd.read_csv('label.csv', header=None).values.flatten()\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# Distance metrics\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Euclidean distance between two points\"\"\"\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    \"\"\"1 - Cosine similarity between two points\"\"\"\n",
    "    dot_product = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if norm_x == 0 or norm_y == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    cosine_sim = dot_product / (norm_x * norm_y)\n",
    "    return 1 - cosine_sim\n",
    "\n",
    "def generalized_jaccard_distance(x, y):\n",
    "    \"\"\"1 - Generalized Jaccard similarity between two points\"\"\"\n",
    "    sum_min = np.sum(np.minimum(x, y))\n",
    "    sum_max = np.sum(np.maximum(x, y))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if sum_max == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    jaccard_sim = sum_min / sum_max\n",
    "    return 1 - jaccard_sim\n",
    "\n",
    "# K-means implementation\n",
    "def kmeans(X, k=3, max_iters=100, distance_metric='euclidean', random_state=None):\n",
    "    \"\"\"\n",
    "    K-means clustering algorithm implementation\n",
    "    \n",
    "    Parameters:\n",
    "    - X: data points (n_samples, n_features)\n",
    "    - k: number of clusters\n",
    "    - max_iters: maximum number of iterations\n",
    "    - distance_metric: 'euclidean', 'cosine', or 'jaccard'\n",
    "    - random_state: random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - centroids: center of clusters\n",
    "    - labels: cluster assignments for each point\n",
    "    - sse: sum of squared errors (inertia)\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Get dimensions\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    idx = np.random.choice(n_samples, k, replace=False)\n",
    "    centroids = X[idx]\n",
    "    \n",
    "    # Choose the distance function\n",
    "    if distance_metric == 'euclidean':\n",
    "        distance_function = euclidean_distance\n",
    "    elif distance_metric == 'cosine':\n",
    "        distance_function = cosine_distance\n",
    "    elif distance_metric == 'jaccard':\n",
    "        distance_function = generalized_jaccard_distance\n",
    "    else:\n",
    "        raise ValueError(\"Unknown distance metric\")\n",
    "    \n",
    "    # Initialize labels\n",
    "    labels = np.zeros(n_samples)\n",
    "    \n",
    "    # Main K-means loop\n",
    "    for _ in range(max_iters):\n",
    "        # Assign points to nearest centroid\n",
    "        new_labels = np.zeros(n_samples)\n",
    "        for i in range(n_samples):\n",
    "            # Calculate distance to each centroid\n",
    "            distances = [distance_function(X[i], centroid) for centroid in centroids]\n",
    "            # Assign to the closest centroid\n",
    "            new_labels[i] = np.argmin(distances)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.all(labels == new_labels):\n",
    "            break\n",
    "        \n",
    "        labels = new_labels\n",
    "        \n",
    "        # Update centroids\n",
    "        for j in range(k):\n",
    "            cluster_points = X[labels == j]\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[j] = np.mean(cluster_points, axis=0)\n",
    "    \n",
    "    # Calculate SSE (Sum of Squared Errors)\n",
    "    sse = 0\n",
    "    for i in range(n_samples):\n",
    "        centroid = centroids[int(labels[i])]\n",
    "        # For SSE calculation, we use squared Euclidean distance regardless of the clustering distance metric\n",
    "        sse += np.sum((X[i] - centroid) ** 2)\n",
    "    \n",
    "    return centroids, labels, sse\n",
    "\n",
    "# Run K-means with each distance metric\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading dataset...\")\n",
    "    X, y = load_dataset('kmeans_data.zip')\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    \n",
    "    # Determine K from the number of unique categories in y\n",
    "    if y is not None:\n",
    "        k = len(np.unique(y))\n",
    "        print(f\"Number of categories in target variable: {k}\")\n",
    "    else:\n",
    "        # Default to 3 if no target variable is found\n",
    "        k = 3\n",
    "        print(f\"No target variable found, using default k={k}\")\n",
    "    \n",
    "    # Run K-means with different distance metrics\n",
    "    metrics = ['euclidean', 'cosine', 'jaccard']\n",
    "    results = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print(f\"\\nRunning K-means with {metric} distance...\")\n",
    "        centroids, labels, sse = kmeans(X, k=k, distance_metric=metric, random_state=42)\n",
    "        \n",
    "        # Count points in each cluster\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        cluster_counts = dict(zip(unique, counts))\n",
    "        \n",
    "        print(f\"Cluster distribution: {cluster_counts}\")\n",
    "        print(f\"Sum of Squared Errors (SSE): {sse:.2f}\")\n",
    "        \n",
    "        results[metric] = {'centroids': centroids, 'labels': labels, 'sse': sse}\n",
    "    \n",
    "    # Compare SSEs and determine the best method\n",
    "    sse_values = {metric: results[metric]['sse'] for metric in metrics}\n",
    "    best_metric = min(sse_values, key=sse_values.get)\n",
    "    \n",
    "    print(\"\\n--- SSE Comparison ---\")\n",
    "    for metric, sse in sse_values.items():\n",
    "        print(f\"{metric.capitalize()}-K-means SSE: {sse:.2f}\")\n",
    "    \n",
    "    print(f\"\\nBased on SSE, the best method is {best_metric.capitalize()}-K-means with SSE = {sse_values[best_metric]:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537fe209-8ae3-442f-bd52-b1e32c01f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Load data and labels\n",
    "with zipfile.ZipFile('kmeans_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "X = pd.read_csv('data.csv', header=None).values\n",
    "y = pd.read_csv('label.csv', header=None).values.flatten()\n",
    "k = len(np.unique(y))\n",
    "\n",
    "# Distance functions\n",
    "def euclidean_distance(x, y): return np.sqrt(np.sum((x - y) ** 2))\n",
    "def cosine_distance(x, y):\n",
    "    dot = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    return 1 - dot / (norm_x * norm_y + 1e-10)\n",
    "def generalized_jaccard_distance(x, y):\n",
    "    return 1 - np.sum(np.minimum(x, y)) / (np.sum(np.maximum(x, y)) + 1e-10)\n",
    "\n",
    "# Basic KMeans\n",
    "def kmeans(X, k=3, max_iters=100, distance_metric='euclidean', random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    centroids = X[np.random.choice(len(X), k, replace=False)]\n",
    "    if distance_metric == 'euclidean':\n",
    "        dist_fn = euclidean_distance\n",
    "    elif distance_metric == 'cosine':\n",
    "        dist_fn = cosine_distance\n",
    "    elif distance_metric == 'jaccard':\n",
    "        dist_fn = generalized_jaccard_distance\n",
    "    labels = np.zeros(len(X))\n",
    "    for _ in range(max_iters):\n",
    "        new_labels = np.array([np.argmin([dist_fn(x, c) for c in centroids]) for x in X])\n",
    "        if np.all(labels == new_labels): break\n",
    "        labels = new_labels\n",
    "        for i in range(k):\n",
    "            points = X[labels == i]\n",
    "            if len(points) > 0:\n",
    "                centroids[i] = points.mean(axis=0)\n",
    "    return centroids, labels\n",
    "\n",
    "# Run KMeans and store results\n",
    "results = {}\n",
    "for metric in ['euclidean', 'cosine', 'jaccard']:\n",
    "    _, labels = kmeans(X, k=k, distance_metric=metric)\n",
    "    results[metric] = {'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0fe168f-561e-4181-af54-baaf68bdab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Accuracy Comparison ---\n",
      "Euclidean-K-means Accuracy: 59.03%\n",
      "Cosine-K-means Accuracy: 63.07%\n",
      "Jaccard-K-means Accuracy: 60.29%\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(true_labels, predicted_clusters):\n",
    "    cluster_to_label = {}\n",
    "    for cluster_id in np.unique(predicted_clusters):\n",
    "        indices = np.where(predicted_clusters == cluster_id)[0]\n",
    "        majority_label = Counter(true_labels[indices]).most_common(1)[0][0]\n",
    "        cluster_to_label[cluster_id] = majority_label\n",
    "    predicted_labels = np.array([cluster_to_label[cluster] for cluster in predicted_clusters])\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy\n",
    "\n",
    "print(\"\\n--- Accuracy Comparison ---\")\n",
    "for metric in ['euclidean', 'cosine', 'jaccard']:\n",
    "    acc = compute_accuracy(y, results[metric]['labels'])\n",
    "    print(f\"{metric.capitalize()}-K-means Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e298e352-2fc4-44ac-ae75-5fe65fd33964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "\n",
    "import time\n",
    "\n",
    "def kmeans(X, k=10, max_iters=100, distance_metric='euclidean', random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    centroids = X[np.random.choice(n_samples, k, replace=False)]\n",
    "\n",
    "    if distance_metric == 'euclidean':\n",
    "        dist_fn = euclidean_distance\n",
    "    elif distance_metric == 'cosine':\n",
    "        dist_fn = cosine_distance\n",
    "    elif distance_metric == 'jaccard':\n",
    "        dist_fn = generalized_jaccard_distance\n",
    "\n",
    "    labels = np.zeros(n_samples)\n",
    "    prev_sse = float('inf')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iteration in range(1, max_iters + 1):\n",
    "        # Assignment step\n",
    "        new_labels = np.array([\n",
    "            np.argmin([dist_fn(x, c) for c in centroids])\n",
    "            for x in X\n",
    "        ])\n",
    "\n",
    "        # Update step\n",
    "        new_centroids = np.copy(centroids)\n",
    "        for j in range(k):\n",
    "            points = X[new_labels == j]\n",
    "            if len(points) > 0:\n",
    "                new_centroids[j] = points.mean(axis=0)\n",
    "\n",
    "        # Compute SSE\n",
    "        current_sse = sum(np.sum((X[new_labels == i] - new_centroids[i])**2) for i in range(k))\n",
    "\n",
    "        # Check stop criteria\n",
    "        if np.allclose(new_centroids, centroids) or current_sse > prev_sse:\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "        labels = new_labels\n",
    "        prev_sse = current_sse\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    return centroids, labels, current_sse, iteration, runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de621711-c342-4b26-a23f-1be78736a66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Convergence Comparison ---\n",
      "Euclidean-K-means → Iterations: 28, Time: 23.64 seconds\n",
      "Cosine-K-means → Iterations: 40, Time: 42.05 seconds\n",
      "Jaccard-K-means → Iterations: 26, Time: 32.00 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Convergence Comparison ---\")\n",
    "for metric in ['euclidean', 'cosine', 'jaccard']:\n",
    "    _, labels, sse, iterations, runtime = kmeans(X, k=k, distance_metric=metric)\n",
    "    print(f\"{metric.capitalize()}-K-means → Iterations: {iterations}, Time: {runtime:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4098b326-f3e5-4b6a-95ae-e43e63e08a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "\n",
    "def kmeans_custom_stop(X, k=10, distance_metric='euclidean', mode='centroid', max_iters=100, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    centroids = X[np.random.choice(n_samples, k, replace=False)]\n",
    "\n",
    "    if distance_metric == 'euclidean':\n",
    "        dist_fn = euclidean_distance\n",
    "    elif distance_metric == 'cosine':\n",
    "        dist_fn = cosine_distance\n",
    "    elif distance_metric == 'jaccard':\n",
    "        dist_fn = generalized_jaccard_distance\n",
    "\n",
    "    labels = np.zeros(n_samples)\n",
    "    prev_sse = float('inf')\n",
    "\n",
    "    for iteration in range(1, max_iters + 1):\n",
    "        new_labels = np.array([\n",
    "            np.argmin([dist_fn(x, c) for c in centroids]) for x in X\n",
    "        ])\n",
    "\n",
    "        new_centroids = np.copy(centroids)\n",
    "        for j in range(k):\n",
    "            cluster_points = X[new_labels == j]\n",
    "            if len(cluster_points) > 0:\n",
    "                new_centroids[j] = np.mean(cluster_points, axis=0)\n",
    "\n",
    "        current_sse = sum(np.sum((X[new_labels == i] - new_centroids[i])**2) for i in range(k))\n",
    "\n",
    "        # Apply stopping condition\n",
    "        if mode == 'centroid' and np.allclose(new_centroids, centroids):\n",
    "            break\n",
    "        elif mode == 'sse' and current_sse > prev_sse:\n",
    "            break\n",
    "        elif mode == 'max' and iteration == max_iters:\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "        labels = new_labels\n",
    "        prev_sse = current_sse\n",
    "\n",
    "    return current_sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da98a544-0867-499d-9620-edfa83f2e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping condition: CENTROID\n",
      "Euclidean: 25410429952.00\n",
      "Cosine: 25471013508.00\n",
      "Jaccard: 25490781886.00\n",
      "\n",
      "Stopping condition: SSE\n",
      "Euclidean: 25491814091.00\n",
      "Cosine: 25425739868.00\n",
      "Jaccard: 25430549479.00\n",
      "\n",
      "Stopping condition: MAX\n",
      "Euclidean: 25389181077.00\n",
      "Cosine: 25427124389.00\n",
      "Jaccard: 25609657930.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modes = ['centroid', 'sse', 'max']\n",
    "metrics = ['euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"\\nStopping condition: {mode.upper()}\")\n",
    "    for metric in metrics:\n",
    "        sse = kmeans_custom_stop(X, k=k, distance_metric=metric, mode=mode)\n",
    "        print(f\"{metric.capitalize()}: {sse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa9640-d0e1-470f-a706-07048ac09806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
